# 黄焖鸡点餐
以一个黄焖鸡餐馆菜单的数据为例，看一下私有知识库的搭建流程。

第一步，将菜单数据整理成固定的输入格式:
```json
{
    "1": {"name": "经典黄焖鸡", "description": "鸡肉鲜嫩，配以浓郁酱汁和土豆", "price": "12元", "category": "主菜"},
    "2": {"name": "辣味黄焖鸡", "description": "经典黄焖鸡基础上加入辣椒调味", "price": "13元", "category": "主菜"},
    "3": {"name": "香菇黄焖鸡", "description": "黄焖鸡加入香菇，风味独特", "price": "14元", "category": "主菜"}
}
```

第二步，将菜单向量化，将类似 item["description"] 这样的本字段转化为向量表示
```python
from transformers import BertModel, BertTokenizer
import torch

# 使用BERT模型
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')


def get_embedding(texts):
    embeddings = []
    for text in texts:
        inputs = tokenizer(text, return_tensors='pt')
        outputs = model(**inputs)
        vector = outputs.last_hidden_state.mean(dim=1).detach().numpy()
        embeddings.append(vector)
    return embeddings


# 读取数据并向量化
with open('huangmenji_menu.json', 'r') as f:
    menu_data = json.loads(f.read())


menu_descriptions = [item["description"] for item in menu_data.values()]
menu_embeddings = get_embedding(menu_descriptions)
```
核心是 get_embedding(menu_descriptions) 这个逻辑。它实现的是文本向量的转化，只有转化为向量数据格式才能在向量数据库做后续操作。


第三步，存储和读取向量数据库，这里以 Milvus向量数据库 为例，注意要将菜单信息和向量信息一起存储，大致代码如下。
```python
from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType, Collection
import numpy as np


# 连接到Milvus
client = MilvusClient(uri="http://localhost:19530", db_name="default")

# 定义集合schema
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
    FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=100),
    FieldSchema(name="description", dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)
]
schema = CollectionSchema(fields, "黄焖鸡餐馆菜单")
index_params = client.prepare_index_params()
index_params.add_index(
    field_name="embedding",
    index_type="IVF_FLAT",
    metric_type="IP",
    params={"nlist": 128}
)


# 创建集合
collection_name = "huangmenji_menu"
client.create_collection(
    collection_name=collection_name,
    schema=schema,
    index_params=index_params
)


# 插入数据
entities = [
    {"id": int(item_id),
     "name": menu_data[item_id]["name"],
     "description": menu_data[item_id]["description"],
     "embedding": menu_embeddings[int(item_id)-1].tolist()}
    for item_id in menu_data
]
client.insert(collection_name=collection_name, data=entities)
```

整个模块最核心的一行代码其实就是这句 FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)。你可以把它理解为传统数据库里的索引。加上这个字段后，后续工作流中需要用到菜单时都可以用向量查询，大致代码如下：
```python
# 查询向量化输入
query = "我喜欢吃辣，有什么菜品推荐"
query_embedding = get_embedding([query])

# 搜索相似的菜单项
res = client.search(
    collection_name=collection_name,
    data=query_embedding,
    limit=3,
    search_params={"metric_type": "IP", "params": {}},
    output_fields=['name', 'description']
)

# 显示结果
for result in res:
    print(f"Found menu item: {result['name']} - {result['description']}")
```
用户的输入例如 “喜欢辣味的菜品” 可能每个人表述不一样。但是同样需求下，通过向量查询就可以找到相似的菜品信息，这正是向量数据库的核心作用。


## 让所有助理可以复用一套知识库逻辑
如果单独针对一个应用开发这样一个知识库是没问题的，但是我们要做的是让所有助理可以复用一套知识库逻辑，因此在实战中，我们会针对这类逻辑开发一个统一的插件。

知识库插件的伪代码如下：
```python
# AI知识库插件
def plugin_ai_knowledge_base_query(query: str, knowledge_base_name: str, field: str) -> str:
    """
    输入：
        query (str) - 用户查询的问题或主题
        knowledge_base_name (str) - 知识库的名称
        field (str) - 需要获取的具体字段名称
    输出：str - 从知识库中获取的相关信息
    """
    # 调用原系统函数获取知识库信息
    return original_system_get_knowledge_base_info(query, knowledge_base_name, field)
```

工作流可以用如下yaml中的伪代码表示：
```yml
version: '1.0'
name: '菜单推荐工作流'
description: '一个基于用户喜好使用AI知识库和自定义逻辑推荐菜品的工作流。'
steps:
  - id: 'input_step'
    type: 'input'
    description: '获取用户对菜品的喜好'
    input:
      description: '用户输入的菜品喜好'
      example: '我喜欢吃辣，有什么菜品推荐'
    output:
      name: 'user_preference'
      type: 'str'


  - id: 'query_knowledge_base'
    type: 'plugin'
    plugin: 'plugin_ai_knowledge_base_query'
    description: '根据用户喜好查询AI知识库中的菜品推荐'
    inputs:
      query: '{user_preference}'
      knowledge_base_name: 'huangmenji_menu'
      # 在这里具体化字段的选择
      field: 'embedding'  # 使用向量数据库的嵌入向量字段进行查询
    outputs:
      name: 'dish_recommendations'
      type: 'str'


  - id: 'custom_logic_filter_spicy'
    type: 'custom'
    function: 'filter_spicy_dishes'
    description: '过滤推荐的菜品，仅保留辣味菜品'
    inputs:
      recommendations: '{dish_recommendations}'
    outputs:
      name: 'spicy_dish_recommendations'
      type: 'list'


  - id: 'output_step'
    type: 'output'
    description: '向用户提供最终的辣味菜品推荐列表'
    inputs:
      spicy_dishes: '{spicy_dish_recommendations}'
    output:
      description: '菜品推荐列表'
      example: ['麻婆豆腐', '辣子鸡', '四川火锅']
```
在这个工作流配置中，query_knowledge_base 是刚才说的插件能力，在用户上传自己的菜单之后可以直接使用，filter_spicy_dishes 则是我们内部针对菜单这个行业场景开发的菜品推荐逻辑，它可以是基于 LLM 开发的。

工作流的背后，实际也是一套代码逻辑。