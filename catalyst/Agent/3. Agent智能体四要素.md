# Agent智能体四要素

<img src="./assets/四要素.png" />

大模型在智能体四要素上的可靠性决定了我们的开发范式。简言之，我们通过编程引导大模型做决策和规划，通过传统程序做执行，在特定的前提和领域下就可以开发足够可靠的 Agent 智能体。

## 案例：一个 LangChain 智能体
下面是一段伪代码，表示根据用户问题查询搜索引擎，最后总结出答案的 Agent 智能体。
```python
from langchain.chains import SimpleChain
from langchain.llms import OpenAI
from langchain.tools import GoogleSearchTool


# 初始化语言模型和工具
llm = OpenAI(api_key="your-api-key")
google_search = GoogleSearchTool(api_key="your-google-api-key")


# 定义Chain
class QuestionAnswerChain(SimpleChain):
    def __init__(self, llm, search_tool):
        self.llm = llm
        self.search_tool = search_tool


    def call(self, input_text):
        # 使用语言模型分析问题
        search_query = self.llm(input_text)
        # 使用搜索工具查找答案
        search_results = self.search_tool(search_query)
        # 通过语言模型总结答案
        answer = self.llm(search_results)
        return answer


# 使用Chain
qa_chain = QuestionAnswerChain(llm, google_search)
user_question = "法国的首都是哪里？?"
answer = qa_chain.call(user_question)
print(answer)
```
例子中的 QuestionAnswerChain 是一个自定义的 Chain，而 Chain 就是 LangChain 框架的核心概念，你可以理解为一个 Chain 就是一个自定义的具备单独能力的智能体。

- 针对用户搜索的输入，通过 self.llm(input_text) 来感知到用户搜索的关键词，这一步是大模型微完成的。
- 第二步用 GoogleSearchTool 查找信息，实际上是我们编程做的决策和规划。
- 最后利用了大模型的语言能力来做输出的执行，也就是 self.llm(search_results)。


总结来说，一个基于 Chain 的简单智能体，其感知、决策、规划、执行，每一步都有我们人类的设定和参与，就能很好的完成这个小任务。